\doxysection{SGD Class Reference}
\hypertarget{classSGD}{}\label{classSGD}\index{SGD@{SGD}}


Stochastic Gradient Descent (\doxylink{classSGD}{SGD}) optimiser.  




{\ttfamily \#include $<$optimiser.\+hpp$>$}

Inheritance diagram for SGD\+:\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[height=2.000000cm]{classSGD}
\end{center}
\end{figure}
\doxysubsubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classSGD_a20541c4b59f2b2caffc9fc5162975d46}{SGD}} (float learning\+\_\+rate)
\begin{DoxyCompactList}\small\item\em Constructor for \doxylink{classSGD}{SGD} optimiser. \end{DoxyCompactList}\item 
void \mbox{\hyperlink{classSGD_a6e909e3d245a8aafa1edf8e5ab602a73}{update\+\_\+weights}} (const \mbox{\hyperlink{classGradients}{Gradients}} \&grads, \mbox{\hyperlink{classNeuralNetwork}{Neural\+Network}} \&nn) override
\begin{DoxyCompactList}\small\item\em Update the weights and biases of the neural network using the gradients. \end{DoxyCompactList}\item 
\Hypertarget{classSGD_a2940e367e1931f174b28f25c1c0831e2}\label{classSGD_a2940e367e1931f174b28f25c1c0831e2} 
{\bfseries \texorpdfstring{$\sim$}{\string~}\+SGD} ()
\begin{DoxyCompactList}\small\item\em Virtual destructor. \end{DoxyCompactList}\item 
float \mbox{\hyperlink{classSGD_aff412cd4938de5105e9f2b3b4ece0665}{get\+\_\+learning\+\_\+rate}} () const override
\begin{DoxyCompactList}\small\item\em Get the learning rate of the optimiser. \end{DoxyCompactList}\end{DoxyCompactItemize}
\doxysubsection*{Public Member Functions inherited from \mbox{\hyperlink{classIOptimiser}{IOptimiser}}}
\begin{DoxyCompactItemize}
\item 
virtual {\bfseries \texorpdfstring{$\sim$}{\string~}\+IOptimiser} ()
\begin{DoxyCompactList}\small\item\em Virtual destructor. \end{DoxyCompactList}\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
Stochastic Gradient Descent (\doxylink{classSGD}{SGD}) optimiser. 

This class implements the \doxylink{classSGD}{SGD} optimisation algorithm for updating the weights and biases of a neural network. It uses an average of the gradients of the batch to update the weights and biases. 

\doxysubsection{Constructor \& Destructor Documentation}
\Hypertarget{classSGD_a20541c4b59f2b2caffc9fc5162975d46}\label{classSGD_a20541c4b59f2b2caffc9fc5162975d46} 
\index{SGD@{SGD}!SGD@{SGD}}
\index{SGD@{SGD}!SGD@{SGD}}
\doxysubsubsection{\texorpdfstring{SGD()}{SGD()}}
{\footnotesize\ttfamily SGD\+::\+SGD (\begin{DoxyParamCaption}\item[{float}]{learning\+\_\+rate }\end{DoxyParamCaption})}



Constructor for \doxylink{classSGD}{SGD} optimiser. 


\begin{DoxyParams}{Parameters}
{\em learning\+\_\+rate} & Learning rate for the optimiser \\
\hline
\end{DoxyParams}


\doxysubsection{Member Function Documentation}
\Hypertarget{classSGD_aff412cd4938de5105e9f2b3b4ece0665}\label{classSGD_aff412cd4938de5105e9f2b3b4ece0665} 
\index{SGD@{SGD}!get\_learning\_rate@{get\_learning\_rate}}
\index{get\_learning\_rate@{get\_learning\_rate}!SGD@{SGD}}
\doxysubsubsection{\texorpdfstring{get\_learning\_rate()}{get\_learning\_rate()}}
{\footnotesize\ttfamily float SGD\+::get\+\_\+learning\+\_\+rate (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [override]}, {\ttfamily [virtual]}}



Get the learning rate of the optimiser. 

\begin{DoxyReturn}{Returns}
Learning rate 
\end{DoxyReturn}


Implements \mbox{\hyperlink{classIOptimiser_a705f5a50c7f09582bc7a0988baa75f93}{IOptimiser}}.

\Hypertarget{classSGD_a6e909e3d245a8aafa1edf8e5ab602a73}\label{classSGD_a6e909e3d245a8aafa1edf8e5ab602a73} 
\index{SGD@{SGD}!update\_weights@{update\_weights}}
\index{update\_weights@{update\_weights}!SGD@{SGD}}
\doxysubsubsection{\texorpdfstring{update\_weights()}{update\_weights()}}
{\footnotesize\ttfamily void SGD\+::update\+\_\+weights (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{classGradients}{Gradients}} \&}]{grads,  }\item[{\mbox{\hyperlink{classNeuralNetwork}{Neural\+Network}} \&}]{nn }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [override]}, {\ttfamily [virtual]}}



Update the weights and biases of the neural network using the gradients. 


\begin{DoxyParams}{Parameters}
{\em grads} & \doxylink{classGradients}{Gradients} for weights and biases \\
\hline
{\em nn} & Neural network to update \\
\hline
\end{DoxyParams}


Implements \mbox{\hyperlink{classIOptimiser_a01a3fa5fd46b6bc1d997aa6aa775f7ec}{IOptimiser}}.



The documentation for this class was generated from the following files\+:\begin{DoxyCompactItemize}
\item 
include/neural\+\_\+network/\mbox{\hyperlink{optimiser_8hpp}{optimiser.\+hpp}}\item 
src/neural\+\_\+network/\mbox{\hyperlink{optimiser_8cpp}{optimiser.\+cpp}}\end{DoxyCompactItemize}
